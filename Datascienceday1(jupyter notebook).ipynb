{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8448d797-f015-45ac-bf4a-adf9239fa138",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Employee Department Quarter  Score\n",
      "2     John         IT      Q1     92\n",
      "4    David      Sales      Q2     95\n",
      "8     Neha      Sales      Q3     99\n",
      "  Employee Department Quarter  Score\n",
      "0     Amit      Sales      Q1     78\n",
      "4    David      Sales      Q2     95\n",
      "8     Neha      Sales      Q3     99\n",
      "  Employee Department Quarter  Score\n",
      "8     Neha      Sales      Q3     99\n",
      "4    David      Sales      Q2     95\n",
      "2     John         IT      Q1     92\n",
      "7     Ravi    Finance      Q2     90\n",
      "3     Sara    Finance      Q1     88\n",
      "1    Priya         HR      Q1     85\n",
      "5    Meera         HR      Q2     80\n",
      "0     Amit      Sales      Q1     78\n",
      "9    Karan         IT      Q3     76\n",
      "6     Alex         IT      Q2     70\n",
      "  Employee Department Quarter  Score\n",
      "7     Ravi    Finance      Q2     90\n",
      "3     Sara    Finance      Q1     88\n",
      "1    Priya         HR      Q1     85\n",
      "5    Meera         HR      Q2     80\n",
      "2     John         IT      Q1     92\n",
      "9    Karan         IT      Q3     76\n",
      "6     Alex         IT      Q2     70\n",
      "8     Neha      Sales      Q3     99\n",
      "4    David      Sales      Q2     95\n",
      "0     Amit      Sales      Q1     78\n",
      "Department\n",
      "Finance    89.000000\n",
      "HR         82.500000\n",
      "IT         79.333333\n",
      "Sales      90.666667\n",
      "Name: Score, dtype: float64\n",
      "Quarter\n",
      "Q1    92\n",
      "Q2    95\n",
      "Q3    99\n",
      "Name: Score, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Scenario: Corporate Employee Performance Dashboard\n",
    "#A company tracks quarterly performance scores of employees across different departments.\n",
    "#The HR analytics team wants to analyze this dataset to identify top performers, departmental trends, and highlight exceptional scores.\n",
    "\n",
    "#Dataset\n",
    "#The dataset contains the following columns:\n",
    "#- Employee: Name of the employee\n",
    "#- Department: Department they belong to (Sales, HR, IT, Finance, etc.)\n",
    "#- Quarter: The quarter in which the performance score was recorded (Q1, Q2, Q3, Q4)\n",
    "#- Score: Performance score (numeric value)\n",
    "\n",
    "#Tasks\n",
    "#- Filtering (Core Corporate Skill)\n",
    "#- Find employees with Score > 90 (exceptional performers).\n",
    "#- Filter records for the Sales department only.\n",
    "#- Sorting (Power Moment)\n",
    "#- Sort employees by Score in descending order to rank performance.\n",
    "#- Sort by Department first, then Score to see departmental rankings.\n",
    "#- Grouping (Core Corporate Skill)\n",
    "#- Group by Department and calculate the average score per department.\n",
    "#- Group by Quarter and find the maximum score achieved in each quarter.\n",
    "\n",
    "#Business Context\n",
    "#- Filtering helps HR identify exceptional performers and focus on specific departments.\n",
    "#- Sorting creates clear performance rankings, useful for promotions or recognition programs.\n",
    "#- Grouping reveals departmental strengths and quarterly performance trends, guiding training and resource allocation.\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"Dataset  - Sheet1.csv\")\n",
    "\n",
    "print(df[df[\"Score\"] > 90])\n",
    "\n",
    "print(df[df[\"Department\"] == \"Sales\"])\n",
    "\n",
    "print(df.sort_values(\"Score\", ascending=False))\n",
    "\n",
    "print(df.sort_values([\"Department\", \"Score\"], ascending=[True, False]))\n",
    "\n",
    "print(df.groupby(\"Department\")[\"Score\"].mean())\n",
    "\n",
    "print(df.groupby(\"Quarter\")[\"Score\"].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e128bcb-49d9-4780-be44-4fc323b3b626",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 5)\n",
      "(8, 6)\n",
      "(8, 4)\n",
      "Index(['CustomerID', 'Name', 'Age', 'Region', 'SignupDate'], dtype='str')\n",
      "Index(['OrderID', 'CustomerID', 'Product', 'Quantity', 'Price', 'OrderDate'], dtype='str')\n",
      "Index(['TicketID', 'CustomerID', 'IssueType', 'ResolutionTime'], dtype='str')\n",
      "CustomerID    0\n",
      "Name          0\n",
      "Age           1\n",
      "Region        0\n",
      "SignupDate    0\n",
      "dtype: int64\n",
      "OrderID       0\n",
      "CustomerID    0\n",
      "Product       0\n",
      "Quantity      0\n",
      "Price         0\n",
      "OrderDate     0\n",
      "dtype: int64\n",
      "TicketID          0\n",
      "CustomerID        0\n",
      "IssueType         0\n",
      "ResolutionTime    0\n",
      "dtype: int64\n",
      "Empty DataFrame\n",
      "Columns: [OrderID, CustomerID, Product, Quantity, Price, OrderDate, DiscountedPrice, Revenue]\n",
      "Index: []\n",
      "  OrderID CustomerID     Product  Quantity  Price  OrderDate  DiscountedPrice  \\\n",
      "0   O1001       C001      Laptop         2  55000 2023-04-10          49500.0   \n",
      "1   O1002       C002      Mobile         1  25000 2023-04-12          22500.0   \n",
      "2   O1003       C003      Tablet         3  15000 2023-05-01          13500.0   \n",
      "3   O1004       C004      Laptop         1  60000 2023-05-15          54000.0   \n",
      "4   O1005       C005      Mobile         2  22000 2023-06-05          19800.0   \n",
      "5   O1006       C006  Headphones         5   2000 2023-06-10           1800.0   \n",
      "6   O1007       C007      Laptop         1  58000 2023-07-02          52200.0   \n",
      "7   O1008       C008      Tablet         2  18000 2023-07-20          16200.0   \n",
      "\n",
      "   Revenue  \n",
      "0   110000  \n",
      "1    25000  \n",
      "2    45000  \n",
      "3    60000  \n",
      "4    44000  \n",
      "5    10000  \n",
      "6    58000  \n",
      "7    36000  \n",
      "  CustomerID   Name   Age Region SignupDate\n",
      "0       C001   Amit  28.0  North 2023-01-15\n",
      "4       C005  David  30.0  North 2023-02-10\n",
      "  OrderID CustomerID Product  Quantity  Price  OrderDate  DiscountedPrice  \\\n",
      "0   O1001       C001  Laptop         2  55000 2023-04-10          49500.0   \n",
      "1   O1002       C002  Mobile         1  25000 2023-04-12          22500.0   \n",
      "2   O1003       C003  Tablet         3  15000 2023-05-01          13500.0   \n",
      "3   O1004       C004  Laptop         1  60000 2023-05-15          54000.0   \n",
      "4   O1005       C005  Mobile         2  22000 2023-06-05          19800.0   \n",
      "6   O1007       C007  Laptop         1  58000 2023-07-02          52200.0   \n",
      "7   O1008       C008  Tablet         2  18000 2023-07-20          16200.0   \n",
      "\n",
      "   Revenue  \n",
      "0   110000  \n",
      "1    25000  \n",
      "2    45000  \n",
      "3    60000  \n",
      "4    44000  \n",
      "6    58000  \n",
      "7    36000  \n",
      "Region\n",
      "East     51500.0\n",
      "North    77000.0\n",
      "South    17500.0\n",
      "West     48000.0\n",
      "Name: Revenue, dtype: float64\n",
      "IssueType\n",
      "Delivery Delay    38.000000\n",
      "Payment Issue     18.666667\n",
      "Product Defect    66.000000\n",
      "Name: ResolutionTime, dtype: float64\n",
      "Cleaned_Data.csv exported successfully\n"
     ]
    }
   ],
   "source": [
    "#Scenario: E‑Commerce Customer & Sales Data Wrangling\n",
    "#An e‑commerce company wants to prepare its raw datasets for a machine learning project that predicts customer purchase behavior. The raw data comes from multiple sources (CSV exports from the sales system, Excel sheets from marketing, and logs from customer support).\n",
    "#The analytics team must clean, transform, and wrangle the data using Pandas before feeding it into ML/DL models.\n",
    "\n",
    "#Dataset Context\n",
    "#- Customers.csv → Customer ID, Name, Age, Region, Signup Date\n",
    "#- Sales.xlsx → Order ID, Customer ID, Product, Quantity, Price, Order Date\n",
    "#- Support.csv → Ticket ID, Customer ID, Issue Type, Resolution Time\n",
    "\n",
    "#Tasks\n",
    "#1. Data Loading\n",
    "#- Load CSV and Excel files into Pandas DataFrames.\n",
    "#- Inspect dataset shapes, column names, and missing values.\n",
    "#2. Array Operations & Broadcasting (NumPy Integration)\n",
    "#- Create a NumPy array of product prices and apply a 10% discount using broadcasting.\n",
    "#- Compute total revenue per order (Quantity × Price).\n",
    "#3. Indexing & Slicing\n",
    "#- Extract all orders placed in January 2025.\n",
    "#- Slice the first 10 rows of the sales dataset for quick inspection.\n",
    "#4. Filtering\n",
    "# Filter customers from the “North” region.\n",
    "# Identify orders with revenue greater than ₹10,000.\n",
    "#5. Sorting\n",
    "#- Sort customers by Signup Date (oldest to newest).\n",
    "#- Sort sales by Revenue in descending order.\n",
    "#6. Grouping\n",
    "# Group sales by Region and calculate average revenue.\n",
    "#- Group support tickets by Issue Type and find average resolution time.\n",
    "#7. Data Wrangling Tasks\n",
    "#- Handle missing values (e.g., fill missing ages with median age).\n",
    "#- Rename columns for clarity (Cust_ID → CustomerID).\n",
    "#- Merge Customers, Sales, and Support datasets on CustomerID.\n",
    "#- Create new calculated fields:\n",
    "#- Customer Lifetime Value (CLV) = total revenue per customer.\n",
    "#- Average Resolution Time per Customer.\n",
    "#- Export the cleaned dataset to Cleaned_Data.csv for ML/DL model training.import pandas as pd\n",
    "    \n",
    "\n",
    "import numpy as np\n",
    "\n",
    "customers = pd.read_csv(\"Customers1 - Sheet1.csv\")\n",
    "sales = pd.read_csv(\"Sales1 - Sheet1.csv\")\n",
    "support = pd.read_csv(\"support1 - Sheet1.csv\")\n",
    "\n",
    "print(customers.shape)\n",
    "print(sales.shape)\n",
    "print(support.shape)\n",
    "\n",
    "print(customers.columns)\n",
    "print(sales.columns)\n",
    "print(support.columns)\n",
    "\n",
    "print(customers.isnull().sum())\n",
    "print(sales.isnull().sum())\n",
    "print(support.isnull().sum())\n",
    "\n",
    "customers[\"SignupDate\"] = pd.to_datetime(customers[\"SignupDate\"])\n",
    "sales[\"OrderDate\"] = pd.to_datetime(sales[\"OrderDate\"])\n",
    "\n",
    "customers[\"Age\"] = customers[\"Age\"].fillna(customers[\"Age\"].median())\n",
    "\n",
    "customers.rename(columns={\"Customer ID\": \"CustomerID\"}, inplace=True)\n",
    "sales.rename(columns={\"Customer ID\": \"CustomerID\"}, inplace=True)\n",
    "support.rename(columns={\"Customer ID\": \"CustomerID\"}, inplace=True)\n",
    "\n",
    "price_array = sales[\"Price\"].to_numpy()\n",
    "sales[\"DiscountedPrice\"] = price_array * 0.9\n",
    "\n",
    "sales[\"Revenue\"] = sales[\"Quantity\"] * sales[\"Price\"]\n",
    "\n",
    "jan_2025_orders = sales[\n",
    "    (sales[\"OrderDate\"].dt.year == 2025) &\n",
    "    (sales[\"OrderDate\"].dt.month == 1)\n",
    "]\n",
    "\n",
    "first_10_sales = sales.iloc[:10]\n",
    "\n",
    "print(jan_2025_orders)\n",
    "print(first_10_sales)\n",
    "\n",
    "north_customers = customers[customers[\"Region\"] == \"North\"]\n",
    "high_value_orders = sales[sales[\"Revenue\"] > 10000]\n",
    "\n",
    "print(north_customers)\n",
    "print(high_value_orders)\n",
    "\n",
    "sorted_customers = customers.sort_values(by=\"SignupDate\")\n",
    "sorted_sales = sales.sort_values(by=\"Revenue\", ascending=False)\n",
    "\n",
    "sales_with_region = sales.merge(customers[[\"CustomerID\", \"Region\"]], on=\"CustomerID\", how=\"left\")\n",
    "\n",
    "avg_revenue_region = sales_with_region.groupby(\"Region\")[\"Revenue\"].mean()\n",
    "avg_resolution_issue = support.groupby(\"IssueType\")[\"ResolutionTime\"].mean()\n",
    "\n",
    "print(avg_revenue_region)\n",
    "print(avg_resolution_issue)\n",
    "\n",
    "merged = sales.merge(customers, on=\"CustomerID\", how=\"left\") \\\n",
    "              .merge(support, on=\"CustomerID\", how=\"left\")\n",
    "\n",
    "clv = sales.groupby(\"CustomerID\")[\"Revenue\"].sum().reset_index()\n",
    "clv.rename(columns={\"Revenue\": \"CLV\"}, inplace=True)\n",
    "\n",
    "avg_res_customer = support.groupby(\"CustomerID\")[\"ResolutionTime\"].mean().reset_index()\n",
    "avg_res_customer.rename(columns={\"ResolutionTime\": \"AvgResolutionTime\"}, inplace=True)\n",
    "\n",
    "final_data = merged.merge(clv, on=\"CustomerID\", how=\"left\") \\\n",
    "                   .merge(avg_res_customer, on=\"CustomerID\", how=\"left\")\n",
    "\n",
    "final_data.to_csv(\"Cleaned_Data.csv\", index=False)\n",
    "\n",
    "print(\"Cleaned_Data.csv exported successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "429167f5-5230-43e9-a4c1-ba138ef75d2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Transaction_ID Customer_ID     Category    Item  Price_Per_Unit  Quantity  \\\n",
      "0               1        C001         Food   Apple             5.0         3   \n",
      "1               2        C002    Furniture   Chair            25.0         1   \n",
      "2               3        C003  Electronics  Laptop           800.0         1   \n",
      "3               4        C004     Clothing   Shirt            20.0         2   \n",
      "4               5        C005         Food   Bread             3.5         5   \n",
      "\n",
      "   Total_Spent Payment_Method  Location Transaction_Date  Discount Region  \n",
      "0         15.0           Cash  In-store       2024-01-01       NaN  South  \n",
      "1         25.0    Credit Card    Online       2024-01-02       NaN   West  \n",
      "2        800.0           Cash  In-store       2024-01-03       NaN   West  \n",
      "3         40.0    Credit Card    Online       2024-01-04      0.15  North  \n",
      "4          NaN           Cash  In-store       2024-01-05      0.00  North  \n",
      "<class 'pandas.DataFrame'>\n",
      "RangeIndex: 20 entries, 0 to 19\n",
      "Data columns (total 12 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   Transaction_ID    20 non-null     int64  \n",
      " 1   Customer_ID       20 non-null     str    \n",
      " 2   Category          20 non-null     str    \n",
      " 3   Item              20 non-null     str    \n",
      " 4   Price_Per_Unit    20 non-null     float64\n",
      " 5   Quantity          20 non-null     int64  \n",
      " 6   Total_Spent       18 non-null     float64\n",
      " 7   Payment_Method    20 non-null     str    \n",
      " 8   Location          20 non-null     str    \n",
      " 9   Transaction_Date  20 non-null     str    \n",
      " 10  Discount          11 non-null     float64\n",
      " 11  Region            20 non-null     str    \n",
      "dtypes: float64(3), int64(2), str(7)\n",
      "memory usage: 2.0 KB\n",
      "None\n",
      "       Transaction_ID  Price_Per_Unit   Quantity  Total_Spent   Discount\n",
      "count        20.00000        20.00000  20.000000    18.000000  11.000000\n",
      "mean         10.50000       122.93500   2.850000   173.366667   0.081818\n",
      "std           5.91608       214.75983   2.560325   286.764829   0.052119\n",
      "min           1.00000         1.20000   1.000000     9.600000   0.000000\n",
      "25%           5.75000         4.75000   1.000000    17.250000   0.050000\n",
      "50%          10.50000        22.50000   2.000000    47.500000   0.100000\n",
      "75%          15.25000       112.50000   3.250000   137.500000   0.110000\n",
      "max          20.00000       800.00000  10.000000  1000.000000   0.150000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"Retail_sales - Sheet1.csv\")\n",
    "\n",
    "print(df.head())\n",
    "print(df.info())\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ed02c9-b94f-4863-bf73-7ee1a3fbd3df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
